apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: loki
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://grafana.github.io/helm-charts
      chart: loki-distributed
      version: 0.74.1
      sourceRef:
        kind: HelmRepository
        name: grafana-charts
        namespace: flux-system
      interval: 5m
  install:
    createNamespace: true
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  values:
    ingester:
      replicas: 3
      maxUnavailable: 1
      podAnnotations:
        container.apparmor.security.beta.kubernetes.io/ingester: runtime/default
      resources:
        limits:
          cpu: 250m
          memory: 300Mi
        requests:
          cpu: 50m
          memory: 100Mi
    querier:
      podAnnotations:
        container.apparmor.security.beta.kubernetes.io/querier: runtime/default
      replicas: 3
      maxUnavailable: 1
      nodeSelector:
        worker: "true"
      resources:
        limits:
          cpu: 2
          memory: 2048Mi
        requests:
          cpu: 50m
          memory: 300Mi
    distributor:
      podAnnotations:
        container.apparmor.security.beta.kubernetes.io/distributor: runtime/default
      nodeSelector:
        worker: "true"
      resources:
        limits:
          cpu: 250m
          memory: 300Mi
        requests:
          cpu: 50m
          memory: 100Mi
    compactor:
      enabled: true
      podAnnotations:
        container.apparmor.security.beta.kubernetes.io/compactor: runtime/default
      nodeSelector:
        worker: "true"
      resources:
        limits:
          cpu: 250m
          memory: 300Mi
        requests:
          cpu: 50m
          memory: 100Mi
    queryFrontend:
      podAnnotations:
        container.apparmor.security.beta.kubernetes.io/query-frontend: runtime/default
      nodeSelector:
        worker: "true"
      resources:
        limits:
          cpu: 250m
          memory: 300Mi
        requests:
          cpu: 50m
          memory: 100Mi
    gateway:
      podAnnotations:
        container.apparmor.security.beta.kubernetes.io/nginx: runtime/default
      nodeSelector:
        worker: "true"
      resources:
        limits:
          cpu: 250m
          memory: 300Mi
        requests:
          cpu: 50m
          memory: 50Mi
      nginxConfig:
        httpSnippet: |
          proxy_read_timeout 600s;
          proxy_connect_timeout 600s;
          proxy_send_timeout 600s;
          send_timeout 600s;


    loki:
      containerSecurityContext:
        readOnlyRootFilesystem: true
        capabilities:
          drop:
            - ALL
        allowPrivilegeEscalation: false
        privileged: false
      podAnnotations:
        seccomp.security.alpha.kubernetes.io/pod: runtime/default
      server:
        log_level: info #TODO: REDUCE
        # Must be set to 3100
        http_listen_port: 3100
        http_server_read_timeout: 15m
        http_server_write_timeout: 15m
      storageConfig:
        aws:
          s3: http://${LOKI_MINIO_USER}:${LOKI_MINIO_PASS}@minio-loki.monitoring.svc.cluster.local.:9000/loki
          insecure: true
          s3forcepathstyle: true



      config: |
        auth_enabled: false

        server:
          {{- toYaml .Values.loki.server | nindent 6 }}

        common:
          compactor_address: http://{{ include "loki.compactorFullname" . }}:3100

        distributor:
          ring:
            kvstore:
              store: memberlist

        memberlist:
          join_members:
            - {{ include "loki.fullname" . }}-memberlist

        ingester_client:
          grpc_client_config:
            grpc_compression: gzip

        ingester:
          lifecycler:
            ring:
              kvstore:
                store: memberlist
              replication_factor: 1
          # Disable chunk transfer which is not possible with statefulsets
          # and unnecessary for boltdb-shipper
          max_transfer_retries: 0
          chunk_idle_period: 30m
          chunk_block_size: 262144
          chunk_encoding: snappy
          chunk_retain_period: 1m
          max_transfer_retries: 0
          wal:
            dir: /var/loki/wal
        querier:
          query_timeout: 15m
          engine:
            timeout: 15m
        limits_config:
          enforce_metric_name: false
          reject_old_samples: true
          reject_old_samples_max_age: 168h
          max_cache_freshness_per_query: 10m
          split_queries_by_interval: 15m

        {{- if .Values.loki.schemaConfig}}
        schema_config:
        {{- toYaml .Values.loki.schemaConfig | nindent 2}}
        {{- end}}
        {{- if .Values.loki.storageConfig}}
        storage_config:
        {{- if .Values.indexGateway.enabled}}
        {{- $indexGatewayClient := dict "server_address" (printf "dns:///%s:9095" (include "loki.indexGatewayFullname" .)) }}
        {{- $_ := set .Values.loki.storageConfig.boltdb_shipper "index_gateway_client" $indexGatewayClient }}
        {{- end}}
        {{- toYaml .Values.loki.storageConfig | nindent 2}}
        {{- if .Values.memcachedIndexQueries.enabled }}
          index_queries_cache_config:
            memcached_client:
              addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedIndexQueriesFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
              consistent_hash: true
        {{- end}}
        {{- end}}

        runtime_config:
          file: /var/{{ include "loki.name" . }}-runtime/runtime.yaml

        chunk_store_config:
          max_look_back_period: 0s
          {{- if .Values.memcachedChunks.enabled }}
          chunk_cache_config:
            embedded_cache:
              enabled: false
            memcached_client:
              consistent_hash: true
              addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedChunksFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
          {{- end }}
          {{- if .Values.memcachedIndexWrites.enabled }}
          write_dedupe_cache_config:
            memcached_client:
              consistent_hash: true
              addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedIndexWritesFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
          {{- end }}

        table_manager:
          retention_deletes_enabled: false
          retention_period: 0s

        query_range:
          align_queries_with_step: true
          max_retries: 5
          cache_results: true
          results_cache:
            cache:
              {{- if .Values.memcachedFrontend.enabled }}
              memcached_client:
                addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedFrontendFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
                consistent_hash: true
              {{- else }}
              embedded_cache:
                enabled: true
                ttl: 24h
              {{- end }}

        frontend_worker:
          {{- if .Values.queryScheduler.enabled }}
          scheduler_address: {{ include "loki.querySchedulerFullname" . }}:9095
          {{- else }}
          frontend_address: {{ include "loki.queryFrontendFullname" . }}-headless:9095
          {{- end }}

        frontend:
          log_queries_longer_than: 5s
          compress_responses: true
          {{- if .Values.queryScheduler.enabled }}
          scheduler_address: {{ include "loki.querySchedulerFullname" . }}:9095
          {{- end }}
          tail_proxy_url: http://{{ include "loki.querierFullname" . }}:3100

        compactor:
          shared_store: s3
          retention_enabled: true
          retention_delete_delay: 2h
          retention_delete_worker_count: 150

        ruler:
          storage:
            type: local
            local:
              directory: /etc/loki/rules
          ring:
            kvstore:
              store: memberlist
          rule_path: /tmp/loki/scratch
          alertmanager_url: https://alertmanager.xx
          external_url: https://alertmanager.xx
